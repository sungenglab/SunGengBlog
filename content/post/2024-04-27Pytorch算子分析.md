---
title:       "深入理解Pytorch源码中的CUDA算子01-BlockReduceSum"
subtitle:    ""
description: "探究下pytorch是如何高效的对一个block中的数据进行规约的"
date:        2024-04-27
author:      SunGeng
image:       ""
tags:        ["CUDA", "Pytorch"]
categories:  ["Tech" ]
---


准备开一个专题，写写pytorch中常用的CUDA算子源码，作为基础储备，索性就从最基础的Reduce操作开始吧！
# 0x00 前言
在神经网络的计算中，对一组数据进行规约是非常常见的操作，譬如规约求和（ReduceSum）、规约求最大最小值（ReduceMax, RedeceMin）等基础算子。 

在CUDA中进行数据规约是每一个CUDA学习者绕不开的训练，在《***CUDA C编程权威指南***》中，以在全局内存中进行规约作为baseline，作者分别介绍如下优化方法：    

1. 避免线程束中的分支分化
2. 使用交错配对而不是相邻配对
3. 使用展开循环
4. 使用模板函数（编译时决定代码分支）
5. 使用共享内存 + 线程展开
6. 使用动态共享内存 + 线程展开

以上优化的具体内容我们这里不表，因为是很基础的操作了，并且在实际项目开发中这些技术也已经过时，不能满足实际需求，感兴趣的可以自行翻阅，只需要理解每一步的优化思路即可，毕竟思路是永不过时的。

这篇博客主要对Pytorch源码中使用的BlockReduceSum CUDA算子进行分析，源码路径如下：
https://github.com/pytorch/pytorch/blob/main/aten/src/ATen/native/cuda/block_reduce.cuh#L71 
# 0x01 Lane & Warp
BlockReduceSum是针对一个Block中的数据进行规约的，因此我们得先介绍CUDA执行模型中的一个重要概念**warp**，我们知道当一个block被调度到一个SM上时，block中的所有threads会被划分为一簇线程束（**warp**），每个**warp**包含连续的32个threads，因此每个block中的线程束数量可以如下计算：    

$$线程块数量 = ceil\begin{pmatrix} \frac {block中的线程数量} {线程束大小}\end{pmatrix}$$        

一个block中最多有1024个threads,线程束大小一般都是32，因此一个block中的线程束数量最多也只有32个。
![warp示意图](/static/markdown_pics/warp.png "一个block中的线程束示意图")
# 0x02 源码分析         
源码：      

    template <typename T, typename B = Block1D>
    __inline__ __device__ T BlockReduceSum(T val, T* shared) {
        const int tid = B::Tid();
        const int lid = tid % C10_WARP_SIZE;
        const int wid = tid / C10_WARP_SIZE;
        val = WarpReduceSum(val);
        __syncthreads(); // prevent races when BlockReduces are called in a row.
        if (lid == 0) {
            shared[wid] = val;
        }
        __syncthreads();
        val = (tid < B::Warps()) ? shared[lid] : T(0);
        if (wid == 0) {
            val = WarpReduceSum(val);
        }
        return val;
    }

首先该函数使用了模板函数，可以。。。，在模板中，**T**为数据类型，**B**为Block线程组织形状，这里默认使用1D的Block单元:               

    struct Block1D {
        static __forceinline__ __device__ int Tid() { return threadIdx.x; }

        static __forceinline__ __device__ int Warps() {
            return blockDim.x / C10_WARP_SIZE;
        }
    };
相应的2D Block单元为：        

    struct Block2D {
        static __forceinline__ __device__ int Tid() {
            return threadIdx.x + threadIdx.y * blockDim.x;
        }

        static __forceinline__ __device__ int Warps() {
            return blockDim.x * blockDim.y / C10_WARP_SIZE;
        }
    };
回到源码继续分析，函数接受两个参数，
# 0x03 kernel调用

# 0x04 参考链接
1. *《CUDA C编程权威指南》*
2. *n*
3. *u*



